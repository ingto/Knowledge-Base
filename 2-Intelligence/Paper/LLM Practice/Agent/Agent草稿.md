- 2023.4，以AutoGPT为代表的Autonomous Agent 热度快速蹿升，AutoGPT成为GitHub历史上star数增长最快的项目。同期比较受关注的类似项目包括：TaskMatrix.ai，HuggingGPT, AgentGPT, Toolformer, BabyAGI等等。
    
- 2023.6，OpenAI 应用研究主管 Lilian Weng 发布博文《LLM Powered Autonomous Agents》进一步推动了agent的热度，Lilian提出**Agent = 大型语言模型+记忆+规划技能+工具使用。**
    
- 多Agent框架相继发布，相对于单一Agent框架能够更好地解决复杂问题。目前比较火的多Agent框架包括：Camel(4月发布，3.4k star), MetaGPT(8月发布，29.7k star), AutoGen(9月发布，微软团队，13.6k star)
    
- 2023.11.6，OpenAI DevDay，推出其官方Agent开发框架Assistant API，赋能开发者更加高效方便地基于GPT模型进行的Agent开发。

**中间层infra**

提供实用可复用的Agent框架，降低开发Agent 的复杂度，并为Agent的合作提供机制设计。该类项目主要从模块化、适配性、协作等几方面进行创新。其中拿到知名机构投资的代表项目包括：AutoGPT、Imbue、Voiceflow、Fixie AI、Reworked、Cognosys、Induced ai等。

  

**Vertical Agent**

深入某个垂直领域，理解该领域专家的工作流，运用Agent 思路设计Copilot产品，用户介入使 Agent思路更为可控。


**Agent适合在哪些场景落地？**

创业者们已经尝试了各种落地场景，总结下来，以下几点更契合Agent的落地。

  

**做到比人（普通员工）****好**

客户不一定要求Agent达到专家水平，很多场合只要比普通员工好就够了。Agent PK的，实际上是月薪几千元的员工。比如，公司IT部门要响应业务人员的各种需求（如临时报表）。如果提供对话式UI，通过几轮对话让业务人员说明白需求，Agent来自动生成，做到这个，客户已经愿意买单了。这样IT团队可以从琐碎中解脱出来，做更重要的事。

  

**Text to SQL**

Text to SQL 在企业落地上有很多案例，以上例子本质上就是Text to SQL, 只不过多了很多新的数据来源：比如从商业化中最值钱的文档（合同、财报、简历、招投标书等）中提取数据。把这些数据连同专家知识一起灌给大模型，把信息抽出来，通过Text to SQL来回答问题，这件事已经很值钱了，可复制性也很强。


**开放场景 vs 封闭场景  
**

Agent的落地效果与场景的封闭程度也很相关。一个典型的对比是Agent在法律助手 vs 出行预订场景。前者场景不够封闭，经常有新知识（如新的法律法规、新的判例）出现，API也不够完善。要做成真正的律师“助手”还有比较大的挑战，比较现实的是做成一个帮助律师整理文档、搜索案例的提效工具。而后者场景封闭（可以穷举）、API丰富（机票、酒店等都有明确的API），在落地中的效果要好很多。最理想的落地情况，是有大量垂直领域数据（给到大模型做预训练）、场景封闭、问题基本可穷举。

**Multi-Agent：为何它的效果明显更好？**

  

最近半年Agent领域一个明显的趋势是“Multi-Agent”框架的流行。很多开发者发现，当事先给Agent设定不同的角色（如产品经理、程序员、UI/UE等等），再让这些Agents一起“协作”完成一个任务时，要比AutoGPT这种单一Agent框架效果好很多，任务完成度更高。相比单一Agent，Multi-Agent除了给大模型设定了角色，好像也没有提供更多的增量信息。为什么这个框架会明显的有效呢？

  

我们认为有如下几点原因：

****角色扮演有引导性，更容易让它聚焦到相关的概率区间****

大模型本质是概率模型，每次输出都不一样。它在训练过程接受了丰富的语料，面对一个问题时，大模型有很多不同的角度和观点，但它自己并不知道应该找哪一个切入。这时如果用户给它一个角色，让它聚焦到一个身份、一种观点上去，它更容易进入到一个与问题相关性更高的概率空间，把其中的专业内容挖掘出来。给大模型一个身份看似没有增量信息，其实一个“角色”背后已经隐含了很多与角色相关的信息。

  

****让大模型做更多的“算力消耗”，System1 vs System2****

OpenAI联创Andrej曾经分享过，他认为Prompt Engineering中思维链（Chain of Thought）之所以有用，就是类似“Let's think step by step“这样的Prompt，让大模型在输出的时候消耗了更多的算力。这点跟人脑类似，人脑在解一个复杂问题时会消耗更多能量。而Multi-Agent正是这样一套能让大模型输出更多、从而消耗更多算力的机制。大模型其实跟人脑的System1类似，特点是不论用户给它的问题难度如何，它的思考时间（对应背后的计算量）是一样的。而目前在Prompt层所做的思维链、Multi-Agent等等工作，都为了让大模型从System1向System2发展，越复杂的问题思考得越久。通过Multi-Agent框架，可以让它消耗更多的算力、做更多思维层次的计算和思考，更有可能更好地解决复杂任务。

这又引申出了许多创业者遇到的一个问题：**并非所有问题都需要System2的能力，如何区分面对的问题需要System 1还是System2解决呢？**如果都用System1的方式解决，那么复杂问题得不到很好的解决；如果都用System2的方式解决，那么又会“杀鸡用牛刀”，既浪费算力、又拉长了反馈时间。最好的方式是能针对问题做好分流。这意味着Agent需要对海量的新问题做实时判断，该用哪种方式解决，而这是绝大多数Agent很难做到的。目前有些创业者在探索先用大模型对问题做一遍意图识别（分类器），再分流到不同的解决方式中去做具体执行。但在很多垂直领域（如法律等），把这个“分类器”做准确的难度依然很大。

****结合多个大模型的最强能力****

前面两个角度，是如何通过Multi-Agent激发大模型发挥能力，背后对应的是一个能力强大的单一大模型。还存在另一种视角，就是Multi-Agent用来结合多个大模型的特色能力。虽然目前OpenAI在大模型领域“一骑绝尘”，我们也观察到其他头部大模型更注重在一些独特能力上的训练（比如更强调与人类的共情能力、更加注重alignment等）。在未来，当这些各有所长的大模型都进入生产，Multi-Agent框架会很方便地融合各家大模型的优势“为我所用”。


**AI Native工作流**

Agent在2B领域落地，目前是按照人类工作的流程切分的，没有考虑到机器，也没有“人机协作”的概念。只是沿用过去的流程把机器加入很可能已经不是最优方式——既无法发挥机器的最大效率，人类员工也不适应。因而做2B场景的Agent，需要重新思考人机协同的工作模式下，什么样的工作流程是最优的，再自上而下地重塑工作流。AI native的工作流应当是什么样？这是个开放性问题，并没有明确的答案，但这个问题可能会定义下一代的企业级软件，是值得现阶段的初创公司去深入思考和探索的重点问题。